{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Update 1 records\n"
     ]
    }
   ],
   "source": [
    "#爬虫爬取过去一年猪肉价格\n",
    "\n",
    "#0.创建数据表\n",
    "import pymysql\n",
    "\n",
    "def create_table():\n",
    "    if not connect_db() == False:\n",
    "        conn, cur = connect_db()\n",
    "        sql = \"\"\"create table copredict_source_pork(\n",
    "                 id int(10) auto_increment primary key,\n",
    "                 date date,\n",
    "                 region varchar(64),\n",
    "                 type varchar(64),\n",
    "                 price float)\"\"\"\n",
    "        cur.execute(sql)\n",
    "    \n",
    "        cur.execute('desc copredict_source_pork')\n",
    "        print(cur.fetchall())\n",
    "\n",
    "#1.数据爬取部分-----------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd   #载入pandas模块\n",
    "import requests       #载入request模块\n",
    "import time           #载入time模块\n",
    "\n",
    "#生成日期列表\n",
    "def dataRange(a,b):    #定义获取日期函数\n",
    "    fmt = '%Y-%m-%d'   #定义返回的日期格式\n",
    "    bgn = int(time.mktime(time.strptime(a,fmt)))  #定义开始日期\n",
    "    end = int(time.mktime(time.strptime(b,fmt)))  #定义结束日期\n",
    "    list_date = [time.strftime(fmt,time.localtime(i))for i in range(bgn,end+1,3600*24)]  #赋值日期表的值，值为日期\n",
    "    return list_date   #返回每一天日期列表\n",
    "\n",
    "\n",
    "    #获得网站回应\n",
    "def get_json(url):                                      #定义获取数据的函数，以json文件返回\n",
    "    headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.106 Safari/537.36'\n",
    "    }                                                  #赋值headers，内容从分析网页的XHR找，以供下面的代码使用\n",
    "    try:                                               #建立try-except，获取数据时防止出错\n",
    "        response = requests.get(url, headers=headers)  #获取数据\n",
    "        if response.status_code == 200:               #如果获取数据请求有回应（成功）\n",
    "            json_text = response.json()               #就用文本返回数据，用json格式保存\n",
    "            return json_text                         #返回此文本格式\n",
    "    except Exception:                                #如果上述情况并未发生（请求失败）\n",
    "        print('An Error has occured on this page!')  #显示“An Error has occured on this page!”\n",
    "        return None                                 #么得返回\n",
    "    \n",
    "    \n",
    "    #获取网页数据\n",
    "def get_contents(url):                        #定义爬虫主函数\n",
    "    doc = get_json(url)                       #使用上述定义的函数获取网址\n",
    "    \n",
    "    dic = {}                                  #定义一个用于储存爬取数据的空字典\n",
    "    dic['pigprice']   =  doc['pigprice']      #获取pigprice数据\n",
    "    #dic['pig_in']     =  doc['pig_in']       #获取pig_in数据\n",
    "    #dic['pig_local']  =  doc['pig_local']    #获取pig_local数据\n",
    "    #dic['maizeprice'] =  doc['maizeprice']   #获取maizeprice数据\n",
    "    #dic['bean']       =  doc['bean']         #获取bean数据\n",
    "  \n",
    "    a = '-'.join(doc['time'][3])                              #取最早的时间\n",
    "    b = time.strftime('%Y-%m-%d',time.localtime(time.time())) #取当前时间\n",
    "    \n",
    "    dic['date'] = dataRange(a,b)                              #取得每一天日期列表\n",
    "    \n",
    "    return pd.DataFrame(dic)                                 #返回带有日期与数据的表格，用pandas格式\n",
    "\n",
    "\n",
    "#2.连接数据库-----------------------------------------------------------------------------------    \n",
    "\n",
    "import pymysql\n",
    "\n",
    "def connect_db():\n",
    "    try:\n",
    "        #建立connect路径\n",
    "        conn = pymysql.connect(host = 'sql.b51.vhostgo.com', db = 'passvisor', user = 'passvisor', password = 'Xudamin123', charset = 'utf8')\n",
    "        #建立cursor\n",
    "        cur = conn.cursor()  \n",
    "        return conn, cur    #返回路径、cursor，供下文使用\n",
    "    except:\n",
    "        return False       #如上述代码请求不成功，返回False字样\n",
    "\n",
    "\n",
    "\n",
    "#3.显示数据-----------------------------------------------------------------------------------    \n",
    "\n",
    "import pymysql\n",
    "\n",
    "def show_table_data(table_name):                #定义显示数据表函数\n",
    "    if not connect_db == False:                #如果连接数据库没有不成功，\n",
    "        sql = 'select * from %s'%(table_name)   #sql指令执行全选数据表内容\n",
    "        conn, cur = connect_db()                #connect路径与cursor来自connect_db()\n",
    "        cur.execute(sql)                        #执行sql指令\n",
    "        print(cur.fetchall())                   #显示所有\n",
    "\n",
    "#4.读取数据表-----------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "def read_table_data(table_name):\n",
    "    if not connect_db() == False:                     #如果连接数据库没有不成功，\n",
    "        conn, cur = connect_db()                       #connect路径与cursor来自connect_db()\n",
    "        sql = 'select * from %s'%(table_name)         #sql指令执行全选数据表内容\n",
    "        db_data = pd.read_sql(sql = sql, con = conn) #用pandas格式读取\n",
    "    return db_data                                  #显示数据\n",
    "\n",
    "#print(readdata())\n",
    "\n",
    "\n",
    "\n",
    "#5.更新数据并写入数据库-----------------------------------------------------------------------------------\n",
    "\n",
    "import pymysql\n",
    "import datetime\n",
    "\n",
    "def updated_data():                       \n",
    "    if not connect_db == False:         #如果连接数据库没有不成功，\n",
    "        conn, cur = connect_db()         #connect路径与cursor来自connect_db() \n",
    "        \n",
    "        s_data = get_contents('https://zhujia.zhuwang.cc/api/chartData?areaId=-1&aa=1581735399831')  #定义s_data为最新爬取的数据\n",
    "        db_data = read_table_data('copredict_source_pork')                                           #定义db_data已有数据\n",
    "        k = 0                                                                                        #赋值k\n",
    "        \n",
    "        for i in range(len(s_data)):                                                                #建立for循环，开始更新数据  \n",
    "            #如果最新爬取的数据记录里的日期没有存在于已有数据内时，（datetime代码为将str转换成datetime.date格式）\n",
    "            if datetime.datetime.strptime(s_data['date'][i], '%Y-%m-%d').date() not in list(db_data['date']):  \n",
    "                #写入该记录\n",
    "                sql = \"insert into copredict_source_pork(date, region, type, price) value('%s', '%s', '%s', %s)\"%(s_data['date'][i], 'GD', 'WSY', s_data['pigprice'][i])\n",
    "                cur.execute(sql)  #执行sql指令\n",
    "                k = k + 1         #为k赋值，若有变化就+1\n",
    "        conn.commit()\n",
    "        print('Done! Update {} records'.format(k))   #显示结果\n",
    "\n",
    "    \n",
    "#6.运行程序-----------------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    updated_data()              #从入口程序运行程序\n",
    "   \n",
    "    #db_data = read_table_data('copredict_source_pork')\n",
    "    \n",
    "    #show_table_data('copredict_source_pork')\n",
    "\n",
    "    #get_contents('https://zhujia.zhuwang.cc/api/chartData?areaId=-1&aa=1581735399831')\n",
    "    \n",
    "    #create_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
